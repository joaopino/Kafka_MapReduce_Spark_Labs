# Introduction

This project was developed in the Lab Classes of the Curricular Unit "Advanced Infrastructures for Data Science" at University of Coimbra in 2024. 

### Requisites

To run the Kafka project, it's needed:
* Functioning Kafka Installation
* Python 3.13 enviornment

To run the Hadoop MapReduce project it's needed:
* Python 3.11 or bellow environment
* MRJob package

To run the Spark Project we used:
* Python 3.13 enviornment
* PySpark with SparkContext, SparkConf and pyspark.sql